{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SJE6_WPb_ot"
      },
      "source": [
        "# Chapter Zero: Facts about sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlbV0Bw_b_o5"
      },
      "source": [
        "## Create a simple if then statement\n",
        "\n",
        "In logic `if... then...` is represented by `->`\n",
        "\n",
        "\n",
        "In python we use an `if... else...` as seen below:\n",
        "\n",
        "```\n",
        "if condition:\n",
        "    do something\n",
        "else:\n",
        "    do something else\n",
        "```\n",
        "\n",
        " The `if` condition is the `if... then...` and the `else` encompases everything past the `if... then...`\n",
        "\n",
        "\n",
        "Below is a simple if else to compare if one quantity is greater than another"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DVvzk-UFb_o7",
        "outputId": "88d2ed54-b924-418c-ffbc-26a9fb8cf715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "a = 2\n",
        "b = 3\n",
        "\n",
        "if a > b:\n",
        "    print(True)\n",
        "else:\n",
        "    print(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBK916Pjb_o_"
      },
      "source": [
        "What if we want to compare all of the operators\n",
        "\n",
        "Not just greater than\n",
        "\n",
        "We would want to make somehting like a general comparison function.\n",
        "\n",
        "Something that took two quantities and an operator then evaluated its truthyness\n",
        "\n",
        "Like this sudo code below:\n",
        "\n",
        "```\n",
        "SUDO CODE\n",
        "if a \"operator\" b then do something\n",
        "\n",
        "where \"operatop\" exists in set {'>','<','>=','<=','=='}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IQUmuXmqb_pD",
        "outputId": "d3beb0c2-780a-450e-fa44-97fed7f12c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2> 3:  False\n",
            "2< 3:  True\n",
            "2>=3:  False\n",
            "2<=3:  True\n",
            "2==3:  False\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "\n",
        "def get_truth(a, op, b):\n",
        "    ops = {'>': operator.gt,\n",
        "           '<': operator.lt,\n",
        "           '>=': operator.ge,\n",
        "           '<=': operator.le,\n",
        "           '==': operator.eq}\n",
        "    # not sure \n",
        "    return ops[op](a, b)\n",
        "\n",
        "print(f\"{a}> {b}:  {get_truth(a, '>', b)}\")\n",
        "print(f\"{a}< {b}:  {get_truth(a, '<', b)}\")\n",
        "print(f\"{a}>={b}:  {get_truth(a, '>=', b)}\")\n",
        "print(f\"{a}<={b}:  {get_truth(a, '<=', b)}\")\n",
        "print(f\"{a}=={b}:  {get_truth(a, '==', b)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YsCKnywb_pI"
      },
      "source": [
        "Here you can see that instead of an `if... else...` statement we use a more general function `get_truth(quantity1, operator, quantity2)`\n",
        "\n",
        "What we can do with this is start to teach computers things about quantities.\n",
        "\n",
        "Really just about numbers since the operators in this settins only work with numerical quantities.\n",
        "\n",
        "This is where the magic happens, we can figure out logic without even having to evaluate the opperand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdKhgY_pb_pJ"
      },
      "source": [
        "## Introduction to simple neural networks\n",
        "\n",
        "A neural network is a simple device that allows you to take an input and produce and output.\n",
        "\n",
        "In this case our network would take an input vector of 2 numbers say `[1,2]` and produce an output vector of booleans e.g. `True` or `False` but for each operator in our operator set `{'>','<','>=','<=','=='}`\n",
        "\n",
        "So essitially if our input is `[1,2]` our output vector would be `[False, True, False, True, False]`. However in order for our simple neural network to read our data we will need to convert our boolean vector to `[0,1,0,1,0]` instead.\n",
        "\n",
        "Since the input will be a 2x1 vecor of dense inputs and the output will be a 5x1 vector of sparse outputs it will be easier to learn dense to sparse, than the other way around.\n",
        "\n",
        "To train a network to learn this code without actually programming the logic, we will need to produce a set of examples.\n",
        "\n",
        "Our input data will be 10k samples of pairs of randomly generated numbers and our output data will be 10k vectors each of length 5.\n",
        "\n",
        "First lets geberate our input, then let's generate our output.\n",
        "\n",
        "### Generating our training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZAmw67oxb_pO",
        "outputId": "22bcd236-1e7a-4567-da94-aa0fbd234a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.85529728, -0.48681754]), array([0, 1, 0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# generate a vector of random number shape (10000,2)\n",
        "input_vec = np.random.randn(10000, 2)\n",
        "\n",
        "# Create a function that take an input pair and prodcues length 5 vector\n",
        "def generate_output(input_vec):\n",
        "    a, b = input_vec\n",
        "    ops = ['>','<','>=','<=','==']\n",
        "    return np.array(\n",
        "        [int(get_truth(a, op, b)) for op in ops]\n",
        "    )\n",
        "\n",
        "# Let's look at the first example that we generated\n",
        "input_vec[0], generate_output(input_vec[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eHJnQN73b_pS",
        "outputId": "c6b056a6-db87-4638-e450-c92725fbe238",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.85529728, -0.48681754],\n",
              "        [ 1.48658393, -0.98458064],\n",
              "        [-1.12342034,  0.45699529],\n",
              "        [-0.59698888, -0.01480697],\n",
              "        [-0.37187381,  0.58280404]]), array([[0, 1, 0, 1, 0],\n",
              "        [1, 0, 1, 0, 0],\n",
              "        [0, 1, 0, 1, 0],\n",
              "        [0, 1, 0, 1, 0],\n",
              "        [0, 1, 0, 1, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Now crete our output that we are interested in learning\n",
        "# by applying the output function along the axis of our input\n",
        "\n",
        "output_vec = np.apply_along_axis(generate_output, 1, input_vec)\n",
        "\n",
        "input_vec[0:5], output_vec[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AS41S7yb_pT"
      },
      "source": [
        "## Building a simple neural network\n",
        "\n",
        "Now that we have generated our training data we can work on:\n",
        "\n",
        "1. putting the data into the proper data format for torch\n",
        "2. create our simple test case network for 2x10x5\n",
        "3. experiment with larger networks if simple network not enough\n",
        "\n",
        "Some of the issues I see arrising from our early network experimentation are that we have very unbalanced class situation meaning that there will be very few or no examples of equality, since they are randomly drawn.\n",
        "\n",
        "Also because it is sample from a random normal the range of the network will be small and useless for larger numbers.\n",
        "\n",
        "However let's experiment and see if any of this is true.\n",
        "\n",
        "Here is our simple neural network:\n",
        "\n",
        "[insert picture here]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to Pytorch\n",
        "\n",
        "[PyTorch](pytorch.org) is cool\n",
        "\n",
        "We'll use it here to create neral networks."
      ],
      "metadata": {
        "id": "vTMXOZs3N4lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create models\n",
        "\n",
        "First lets check which device we are using"
      ],
      "metadata": {
        "id": "2lCcX21jUwvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmUHjC8nUE4U",
        "outputId": "6b635209-89db-4844-c7d1-91d698d4ab85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are not using the GPU yet becuase we don't have any networks to accelerate."
      ],
      "metadata": {
        "id": "HT0FxpYapwZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(2,10),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10, 5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "R8EsM-lYUYlz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the most simple class based method code. Personally I am used to the functional method as I used in [this repo](https://github.com/rcgalbo/xor_example).\n",
        "\n",
        "It is still pretty self explanatory. We define our class which is `NeuralNetwork` that extends the `torch.nn.Module` class. All that means is that there is a thing called `torch.nn.Module` and now our class `NeuralNetwork` is that thing too. We could have called it anything this is just straight coppied from the torch docs.\n",
        "\n",
        "Then we du this thing `super().__init__()` which I am pretty sure is juist a way of initializing the class `torch.nn.Module`. Don't hurt your brain thinking about it too much just remeber you have to type that first in your `__init__(self)`. `nn.Flatten()` does exactly what it sounds like. I think that means it flattens.\n",
        "\n",
        "Here is where it gets interesting. We pack all of our network code inside of `self.linear_relu_stack` by calling `nn.Sequential()` which is saying that we will pass all of our data through our network sequentially. Inside of that `nn.Sequential()` is our layer definition function\n",
        "\n",
        "```\n",
        "  nn.Linear(2,10),                # input 2 dims, output 10 dims\n",
        "  nn.ReLU(),                      # Rectified Linear Unit Activation \n",
        "  nn.Linear(10, 5),               # input 10 dims, output 5 dims\n",
        "```"
      ],
      "metadata": {
        "id": "GSbASAI7waO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "294j9G-3UkP_",
        "outputId": "6b5b44c5-02a1-4850-bd1b-0be614724889"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=10, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizing parameters\n",
        "\n",
        "We need something called a loss function that specifies how we will peanalize the model for being wrong. \n",
        "\n",
        "We will use the function `nn.CrossEntropyLoss()` as our loss function\n",
        "\n",
        "We will also use SGD as our optimizer"
      ],
      "metadata": {
        "id": "bFJtA3a0saq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "08fg-GepySsm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Loop\n",
        "\n",
        "Here is where the magic happens and the model parameters are updated by our optimizer gradient descent."
      ],
      "metadata": {
        "id": "YpZrRbt1yZYy"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "math_logic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6c47c6a4b08e1ef3ae15ef1b034b2e0b06c49a5e0b38b824d30a3e22dc0e98d6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}